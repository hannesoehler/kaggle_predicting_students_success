{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A LightGBM model to predict students' success <br>\n",
    "\n",
    "This LightGBM model for classification includes 45 features:\n",
    "\n",
    "#### - Features on questions' characteristics:\n",
    "\n",
    "answered_correctly_mean: Difficulty of the current question (share of correct answers by all users) <br>\n",
    "previous_questions_difficulty: Difficulty of previous questions answered by a user <br>\n",
    "answered_correctly_mean_std: Standard deviation of the question's share of correct answeres by all users <br>\n",
    "answered_correctly_mean_bundle: Share of questions answered correctly in a specific question bundle <br>\n",
    "\n",
    "tag1: First tag of the current question <br>\n",
    "tag2: Second tag of the current question <br>\n",
    "tag3: Third tag of the current question <br>\n",
    "part: Category of the current question <br>\n",
    "\n",
    "question_clusters: Clustering of questions according to conditional probabilities with respect to the 20 questions most frequently asked <br>\n",
    "question_clusters_2: Clustering of questions with respect to other features (independently of the question's share of correct answers)\n",
    "\n",
    "#### - Features on user's history:\n",
    "\n",
    "previous_questions: Number of previously answered questions by the user <br>\n",
    "answered_correctly_lagged_sum: Number of previous questions answered correctly by the user <br>\n",
    "\n",
    "previous_answered_correctly: User's knowledge (User's share of correct answers in the past) <br>\n",
    "previous_answered_correctly_rolling: Rolling window of user's share of correct answers (last 350 interactions) <br>\n",
    "previous_answered_correctly_rolling_200: Rolling window of user's share of correct answers (last 200 interactions) <br>\n",
    "previous_answered_correctly_rolling_100: Rolling window of user's share of correct answers (last 100 interactions) <br>\n",
    "previous_answered_correctly_rolling_50: Rolling window of user's share of correct answers (last 50 interactions) <br>\n",
    "previous_answered_correctly_rolling_20: Rolling window of user's share of correct answers (last 20 interactions) <br>\n",
    "previous_answered_correctly_rolling_10: Rolling window of user's share of correct answers (last 10 interactions)\n",
    "\n",
    "prev_que_answ_corr: Difficulty of previous questions answered correctly <br>\n",
    "prev_que_answ_incorr: Difficulty of previous questions answered incorrectly <br>\n",
    "prev_que_answ_corr_min: Max. difficulty of previous questions answered correctly <br>\n",
    "prev_que_answ_incorr_max: Min. difficulty of previous questions answered incorrectly <br>\n",
    "\n",
    "time_between_questions: Time between current and last question <br>\n",
    "time_between_questions_2lag': Time between current and second-last question <br>\n",
    "time_between_questions_3lag': Time between current and third-last question <br>\n",
    "time_between_questions_4lag': Time between current and fourth-last question <br>\n",
    "time_between_questions_5lag': Time between current and fifth-last question <br>\n",
    "time_between_questions_6lag': Time between current and sixth-last question <br>\n",
    "time_between_questions_7lag': Time between current and seventh-last question <br>\n",
    "timediff_last_corr_answ: Time between current and last question answered correctly <br>\n",
    "timediff_last_incorr_answ: Time between current and last question answered incorrectly <br>\n",
    "timediff_2_last_incorr_answ': Time between current and second-last question answered incorrectly <br>\n",
    "timediff_3_last_incorr_answ': Time between current and third-last question answered incorrectly <br>\n",
    "timediff_4_last_incorr_answ': Time between current and fourth-last question answered incorrectly <br>\n",
    "\n",
    "prior_question_elapsed_time: (Average) time spent on each question of the brevious task container <br>\n",
    "prior_question_elapsed_time_sum: Sum of the time spent on answering questions in the past <br>\n",
    "prior_question_elapsed_time_mean': Sum / Number of questions answered in the past <br>\n",
    "prior_question_had_explanation_mean': Average of whether previous questions had an explanation <br>\n",
    " \n",
    "repeated_question_corr: Current question seen in the past and answered correctly <br>\n",
    "repeated_question_exp: Current question seen in the past and it had an explanation <br>\n",
    "repeated_question_time: Time between the current question and when it has been seen in the past <br>\n",
    "\n",
    "answer_share: Share of user's answer choice in the past with respect to the correct answer <br>\n",
    " \n",
    "repeated_tags_correct_share: Share of questions of the respective tag answered correctly in the past <br>\n",
    "tag_timediff: Time between the current question and a question with the respective tag in the past <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gc\n",
    "from collections import defaultdict, deque\n",
    "from bitarray import bitarray\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    \"row_id\": \"int64\",\n",
    "    \"timestamp\": \"int64\",\n",
    "    \"user_id\": \"int32\",\n",
    "    \"content_id\": \"int16\",\n",
    "    \"content_type_id\": \"int8\",\n",
    "    \"task_container_id\": \"int16\",\n",
    "    \"answered_correctly\": \"int8\",\n",
    "    \"user_answer\": \"int8\",\n",
    "    \"prior_question_elapsed_time\": \"float32\", \n",
    "    \"prior_question_had_explanation\": \"int8\"\n",
    "    }\n",
    "\n",
    "data = pd.read_csv('train.csv', dtype=dtypes, usecols=[\"row_id\",\"user_id\",\"task_container_id\",\"timestamp\",\n",
    "                    \"content_id\",\"content_type_id\",\"answered_correctly\",\"user_answer\",\n",
    "                        \"prior_question_elapsed_time\",\"prior_question_had_explanation\"], nrows=10**5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['content_type_id']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_questions = list(data['content_id'].value_counts().index.tolist())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = data['user_id'].values\n",
    "questions = data['content_id'].values\n",
    "y = data['answered_correctly'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_question_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(int))))\n",
    "\n",
    "for i, (user_id, content_id, answ_corr) in enumerate(zip(tqdm(users), questions, y)):\n",
    "\n",
    "    for que in most_freq_questions:\n",
    "        if sim_question_dict[user_id][que]['correct']==1:\n",
    "            sim_question_dict[que][content_id]['correct']['answered_correctly'] += answ_corr\n",
    "            sim_question_dict[que][content_id]['correct']['previous_questions'] += 1\n",
    "\n",
    "        elif sim_question_dict[user_id][que]['correct']==-1:\n",
    "            sim_question_dict[que][content_id]['incorrect']['answered_correctly'] += answ_corr\n",
    "            sim_question_dict[que][content_id]['incorrect']['previous_questions'] += 1\n",
    "\n",
    "    if content_id in most_freq_questions:\n",
    "        if answ_corr == 1:\n",
    "            sim_question_dict[user_id][content_id]['correct']=1\n",
    "        else:\n",
    "            sim_question_dict[user_id][content_id]['correct']=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_dict = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for i, (content_id, answ_corr) in enumerate(zip(tqdm(questions), y)):\n",
    "    question_dict[content_id]['previous_questions_content'] += 1\n",
    "    question_dict[content_id]['answered_correctly_content_sum'] += answ_corr\n",
    "    question_dict[content_id]['answered_correctly_mean'] = question_dict[content_id][\n",
    "        'answered_correctly_content_sum'] / question_dict[content_id]['previous_questions_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_question_corr = np.zeros((13523,20), dtype=np.float32)\n",
    "cluster_question_incorr = np.zeros((13523,20), dtype=np.float32)\n",
    "\n",
    "for i, content_id in enumerate(tqdm(questions)):\n",
    "    for j, que in enumerate(most_freq_questions):\n",
    "        if sim_question_dict[que][content_id]['correct']['previous_questions']>0:\n",
    "            cluster_question_corr[content_id,j] = (sim_question_dict[que][\n",
    "                content_id]['correct']['answered_correctly']/sim_question_dict[que][content_id]['correct'][\n",
    "                'previous_questions']) - question_dict[content_id]['answered_correctly_mean'] \n",
    "        else:\n",
    "            cluster_question_corr[content_id,j] = np.nan\n",
    "        if sim_question_dict[que][content_id]['incorrect']['previous_questions']>0:\n",
    "            cluster_question_incorr[content_id,j] = (sim_question_dict[que][content_id][\n",
    "                'incorrect']['answered_correctly']/sim_question_dict[que][content_id]['incorrect'][\n",
    "                'previous_questions']) - question_dict[content_id]['answered_correctly_mean']\n",
    "        else:\n",
    "            cluster_question_incorr[content_id,j] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.nan_to_num(np.concatenate((cluster_question_corr,cluster_question_incorr), axis=1))\n",
    "\n",
    "clustering = KMeans(30, n_init=100, max_iter=1000)\n",
    "cluster_groups_questions = clustering.fit_predict(X)\n",
    "\n",
    "question_clusters_dict = pd.Series(cluster_groups_questions).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random user sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = data['user_id'].unique()\n",
    "random.seed(52)\n",
    "user_list = random.sample(list(user_list), len(user_list))\n",
    "\n",
    "train_split = int(len(user_list)*0.5)\n",
    "user_list = user_list[train_split:]\n",
    "\n",
    "data = data.loc[data['user_id'].isin(user_list),:]\n",
    "\n",
    "del user_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_csv('questions.csv')\n",
    "\n",
    "tags_len_max = questions['tags'].apply(lambda x: len(str(x).split())).max()\n",
    "\n",
    "for i in range(1, tags_len_max + 1):\n",
    "    questions['tag{}'.format(i)] = questions['tags'][questions['tags'].isnull()==0].apply(lambda x: int(str(x\n",
    "                                                        ).split()[i-1]) if len(str(x).split()) >= i else 0)\n",
    "\n",
    "questions = questions.rename(columns={'question_id':'content_id'})\n",
    "questions.set_index('content_id', inplace=True)\n",
    "\n",
    "data = data.merge(data.loc[data['content_type_id']==0,:].merge(questions, on='content_id', how='left')[[\n",
    "    'row_id','bundle_id','correct_answer','part','tag1','tag2','tag3']], on='row_id', how='left')\n",
    "del questions\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cont = data.groupby(['user_id','task_container_id'])[\n",
    "    'prior_question_had_explanation','prior_question_elapsed_time'].mean()\n",
    "data_cont = data_cont.groupby('user_id')['prior_question_had_explanation','prior_question_elapsed_time'].shift(\n",
    "    -1)\n",
    "data_cont.rename(columns={'prior_question_had_explanation':'question_had_explanation',\n",
    "                     'prior_question_elapsed_time':'question_elapsed_time'}, inplace=True)\n",
    "data = data.join(data_cont, on=['user_id','task_container_id'], how='left')\n",
    "\n",
    "del data_cont\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV strategy\n",
    "\n",
    "The CV strategy is based on: https://www.kaggle.com/its7171/cv-strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(52)\n",
    "\n",
    "users_random_start=defaultdict(int)\n",
    "\n",
    "timestamp_max_user = data.groupby('user_id')['timestamp'].max().reset_index()\n",
    "timestamp_max = data['timestamp'].max()\n",
    "\n",
    "for user_id, timestamp in zip(tqdm(timestamp_max_user['user_id'].values), timestamp_max_user['timestamp'\n",
    "    ].values):\n",
    "    users_random_start[user_id] = random.randint(0, timestamp_max - timestamp)\n",
    "\n",
    "est_time = np.empty(len(data))\n",
    "for i, (timestamp, user_id) in enumerate(zip(tqdm(data['timestamp'].values), data['user_id'].values)):\n",
    "    est_time[i] = timestamp + users_random_start[user_id]\n",
    "data['est_time'] = est_time\n",
    "\n",
    "del timestamp_max_user\n",
    "del users_random_start\n",
    "del est_time\n",
    "gc.collect()\n",
    "\n",
    "data.sort_values('est_time', inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data.loc[int(len(data)*0.95):,'train_val_split']=1\n",
    "data.loc[:int(len(data)*0.95),'train_val_split']=0\n",
    "\n",
    "data.sort_values(['user_id','timestamp'], inplace=True)\n",
    "\n",
    "train_val_split = data['train_val_split'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_position = dict(zip(['answered_correctly_mean', 'previous_answered_correctly','previous_questions',\n",
    "        'previous_questions_difficulty','prev_que_answ_corr','prev_que_answ_incorr','tag1','tag2','tag3',\n",
    "        'part','time_between_questions','prior_question_elapsed_time','prior_question_elapsed_time_mean',\n",
    "            'prior_question_had_explanation_mean','answered_correctly_lagged_sum','repeated_question_corr',\n",
    "            'repeated_question_exp','repeated_question_time','answer_share','prior_question_elapsed_time_sum',\n",
    "            'prev_que_answ_corr_min','prev_que_answ_incorr_max','previous_answered_correctly_rolling',\n",
    "            'answered_correctly_mean_std','answered_correctly_mean_bundle','timediff_last_corr_answ',\n",
    "            'timediff_last_incorr_answ','time_between_questions_2lag','timediff_2_last_incorr_answ',\n",
    "            'time_between_questions_3lag','timediff_3_last_incorr_answ','time_between_questions_4lag',\n",
    "            'timediff_4_last_incorr_answ','time_between_questions_5lag','time_between_questions_6lag',\n",
    "            'time_between_questions_7lag','previous_answered_correctly_rolling_200',\n",
    "            'previous_answered_correctly_rolling_100','previous_answered_correctly_rolling_50',\n",
    "            'previous_answered_correctly_rolling_20','previous_answered_correctly_rolling_10',\n",
    "            'repeated_tags_correct_share','tag_timediff','question_clusters','question_clusters_2'\n",
    "            ],list(range(45))))\n",
    "            \n",
    "features = np.zeros([len(data),45], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = data['user_id'].values\n",
    "questions = data['content_id'].values\n",
    "bundles= data['bundle_id'].values\n",
    "y = data['answered_correctly'].values\n",
    "user_answer = data['user_answer'].values\n",
    "timestamp = data['timestamp'].values\n",
    "prior_question_had_explanation = data['prior_question_had_explanation'].values\n",
    "question_had_explanation = data['question_had_explanation'].values\n",
    "question_elapsed_time = data['question_elapsed_time'].values\n",
    "\n",
    "task_container = data['task_container_id'].values\n",
    "\n",
    "correct_answer = data['correct_answer']\n",
    "tag1 = data['tag1'].fillna(-1).astype('int').values\n",
    "\n",
    "user_lookup = pd.Series(data['user_id'].unique()).to_dict()\n",
    "user_lookup = {k: v for v, k in user_lookup.items()}\n",
    "\n",
    "tag1_lookup = pd.Series(data['tag1'].fillna(-1).astype('int').unique()).to_dict()\n",
    "tag1_lookup = {k: v for v, k in tag1_lookup.items()}\n",
    "\n",
    "features[:,feature_position['tag1']] = data['tag1'].values\n",
    "features[:,feature_position['tag2']] = data['tag2'].values\n",
    "features[:,feature_position['tag3']] = data['tag3'].values\n",
    "features[:,feature_position['part']] = data['part'].values\n",
    "features[:,feature_position['prior_question_elapsed_time']] = data['prior_question_elapsed_time'].values\n",
    "\n",
    "features = features.astype(np.float32)\n",
    "\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_dict = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for i, (content_id, answ_corr, elap_time) in enumerate(zip(tqdm(questions), y, question_elapsed_time)):\n",
    "    question_dict[content_id]['previous_questions_content'] += 1\n",
    "    question_dict[content_id]['answered_correctly_content_sum'] += answ_corr\n",
    "    question_dict[content_id]['answered_correctly_mean'] = question_dict[content_id][\n",
    "        'answered_correctly_content_sum'] / question_dict[content_id]['previous_questions_content']\n",
    "    features[i,feature_position['question_clusters']] = question_clusters_dict[content_id]+1\n",
    "\n",
    "for i, (content_id, answ_corr) in enumerate(zip(tqdm(questions), y)):\n",
    "    features[i,feature_position['answered_correctly_mean']]=question_dict[content_id]['answered_correctly_mean']\n",
    "    question_dict[content_id]['answered_correctly_mean_std_to_norm'] += (answ_corr - question_dict[content_id]['answered_correctly_mean'])**2\n",
    "\n",
    "for i, content_id in enumerate(tqdm(questions)):\n",
    "    features[i,feature_position['answered_correctly_mean_std']]=question_dict[content_id][\n",
    "        'answered_correctly_mean_std_to_norm'] / question_dict[content_id]['previous_questions_content'] \n",
    "del question_dict\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_dict = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for i, (bundle_id, answ_corr) in enumerate(zip(tqdm(bundles), y)):\n",
    "    bundle_dict[bundle_id]['previous_questions_content'] += 1\n",
    "    bundle_dict[bundle_id]['answered_correctly_content_sum'] += answ_corr\n",
    "    bundle_dict[bundle_id]['answered_correctly_mean'] = bundle_dict[bundle_id]['answered_correctly_content_sum'] / bundle_dict[bundle_id][\n",
    "        'previous_questions_content']\n",
    "    \n",
    "for i, (bundle_id, answ_corr) in enumerate(zip(tqdm(bundles), y)):\n",
    "    features[i,feature_position['answered_correctly_mean_bundle']]=bundle_dict[bundle_id]['answered_correctly_mean']\n",
    "    \n",
    "del bundle_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_content_dict = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for i, (user_id, content_id, answ_corr, exp, time) in enumerate(zip(tqdm(users),questions, y, question_had_explanation,\n",
    "                                                             timestamp)):  \n",
    "    if user_id not in user_content_dict:\n",
    "        user_content_dict[user_id]['answ_corr'] = bitarray(13523, endian='little')\n",
    "        user_content_dict[user_id]['answ_corr'].setall(0)\n",
    "        user_content_dict[user_id]['exp'] = bitarray(13523, endian='little')\n",
    "        user_content_dict[user_id]['exp'].setall(0)\n",
    "\n",
    "    features[i,feature_position['repeated_question_corr']] = user_content_dict[user_id]['answ_corr'][content_id]\n",
    "    features[i,feature_position['repeated_question_exp']] = user_content_dict[user_id]['exp'][content_id]\n",
    "    \n",
    "    if user_content_dict[user_id][content_id] > 0:\n",
    "        features[i,feature_position['repeated_question_time']] = time - user_content_dict[user_id][content_id]\n",
    "    else:\n",
    "        features[i,feature_position['repeated_question_time']] = np.nan\n",
    "\n",
    "    user_content_dict[user_id]['answ_corr'][content_id] = answ_corr\n",
    "    user_content_dict[user_id]['exp'][content_id] = exp\n",
    "    user_content_dict[user_id][content_id] = time\n",
    "\n",
    "del user_content_dict\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tag1_matrix = np.zeros((len(user_lookup), len(tag1_lookup)), dtype=np.int16)\n",
    "user_tag1_corr_matrix = np.zeros((len(user_lookup), len(tag1_lookup)), dtype=np.int16)\n",
    "user_tag1_time_matrix = np.zeros((len(user_lookup), len(tag1_lookup)), dtype=np.int64)\n",
    "\n",
    "for i, (user_id, t1, answ_corr, time) in enumerate(zip(tqdm(users),tag1, y, timestamp)):\n",
    "    features[i,feature_position['repeated_tags_correct_share']] = user_tag1_corr_matrix[user_lookup[user_id\n",
    "                    ],tag1_lookup[t1]] / user_tag1_matrix[user_lookup[user_id],tag1_lookup[t1]]\n",
    "    \n",
    "    if user_tag1_time_matrix[user_lookup[user_id],tag1_lookup[t1]] > 0:\n",
    "        features[i,feature_position['tag_timediff']] = time - user_tag1_time_matrix[user_lookup[user_id\n",
    "                                                        ],tag1_lookup[t1]]\n",
    "    else: \n",
    "        features[i,feature_position['tag_timediff']] = np.nan\n",
    "        \n",
    "    user_tag1_matrix[user_lookup[user_id],tag1_lookup[t1]] += 1\n",
    "    user_tag1_corr_matrix[user_lookup[user_id],tag1_lookup[t1]] += answ_corr\n",
    "    user_tag1_time_matrix[user_lookup[user_id],tag1_lookup[t1]] = time\n",
    "    \n",
    "del user_tag1_matrix\n",
    "del user_tag1_corr_matrix\n",
    "del user_tag1_time_matrix\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for i, (user_id, content_id, answ_corr, que_corr, time, exp, elap_time, user_answ, corr_answ, task_id\n",
    "       ) in enumerate(zip(tqdm(users), questions, y, features[:,feature_position['answered_correctly_mean'\n",
    "        ]], timestamp, prior_question_had_explanation, features[:,feature_position[\n",
    "        'prior_question_elapsed_time']],user_answer,correct_answer, task_container)):\n",
    "           \n",
    "    user_dict[user_id]['previous_questions'] += 1\n",
    "    user_dict[user_id]['answer_{}'.format(user_answ)] += 1\n",
    "    user_dict[user_id]['answered_correctly'] =answ_corr\n",
    "    \n",
    "    user_dict[user_id]['answered_correctly_sum'] += answ_corr\n",
    "    user_dict[user_id]['answered_incorrectly_sum'] += (1-answ_corr)\n",
    "    \n",
    "    if user_dict[user_id]['previous_questions'] == 1:\n",
    "        features[i,feature_position['time_between_questions']] = np.nan\n",
    "        features[i,feature_position['timediff_last_corr_answ']] = np.nan\n",
    "        features[i,feature_position['timediff_last_incorr_answ']] = np.nan\n",
    "        \n",
    "        for l in range(2,8):\n",
    "            features[i,feature_position['time_between_questions_{}lag'.format(l)]] = np.nan\n",
    "        for l in range(2,5):    \n",
    "            features[i,feature_position['timediff_{}_last_incorr_answ'.format(l)]] = np.nan\n",
    "        \n",
    "        features[i,feature_position['previous_questions']]=0\n",
    "        features[i,feature_position['answered_correctly_lagged_sum']]=np.nan\n",
    "        features[i,feature_position['previous_answered_correctly']]=np.nan\n",
    "        features[i,feature_position['previous_questions_difficulty']]=np.nan\n",
    "        features[i,feature_position['prev_que_answ_corr']]=np.nan\n",
    "        features[i,feature_position['prev_que_answ_incorr']]=np.nan\n",
    "        \n",
    "        features[i,feature_position['prev_que_answ_corr_min']] = np.nan\n",
    "        features[i,feature_position['prev_que_answ_incorr_max']] = np.nan\n",
    "        \n",
    "        features[i,feature_position['answer_share']]=np.nan\n",
    "        \n",
    "        features[i,feature_position['previous_answered_correctly_rolling']] = np.nan\n",
    "        features[i,feature_position['previous_answered_correctly_rolling_200']] = np.nan\n",
    "        features[i,feature_position['previous_answered_correctly_rolling_100']] = np.nan\n",
    "        features[i,feature_position['previous_answered_correctly_rolling_50']] = np.nan\n",
    "        features[i,feature_position['previous_answered_correctly_rolling_20']] = np.nan\n",
    "        features[i,feature_position['previous_answered_correctly_rolling_10']] = np.nan\n",
    "        \n",
    "        user_dict[user_id]['prior_question_elapsed_time_sum'] = 0\n",
    "        \n",
    "        user_dict[user_id]['prior_question_elapsed_time_mean'] = np.nan\n",
    "        user_dict[user_id]['prior_question_had_explanation_mean'] = np.nan\n",
    "        \n",
    "        user_dict[user_id]['answered_correctly_history']=bitarray()\n",
    "        user_dict[user_id]['answered_correctly_history'].append(answ_corr)\n",
    "        \n",
    "        user_dict[user_id]['timestamp_lst'] = deque([], maxlen=7)\n",
    "        user_dict[user_id]['timestamp_answ_corr']=deque([],maxlen=1)\n",
    "        user_dict[user_id]['timestamp_answ_incorr']=deque([],maxlen=4)\n",
    "              \n",
    "    else:\n",
    "        features[i,feature_position['time_between_questions']] = time - user_dict[user_id]['timestamp']\n",
    "        try:\n",
    "            features[i,feature_position['timediff_last_corr_answ']] = time - user_dict[user_id][\n",
    "            'timestamp_answ_corr'][-1]\n",
    "        except: \n",
    "            features[i,feature_position['timediff_last_corr_answ']] = np.nan\n",
    "        try:\n",
    "            features[i,feature_position['timediff_last_incorr_answ']] = time - user_dict[user_id][\n",
    "                'timestamp_answ_incorr'][-1]\n",
    "        except:\n",
    "            features[i,feature_position['timediff_last_incorr_answ']] = np.nan\n",
    "        \n",
    "        for l in range(2,8):\n",
    "            if user_dict[user_id]['previous_questions'] <= l:\n",
    "                features[i,feature_position['time_between_questions_{}lag'.format(l)]] = np.nan\n",
    "            else:\n",
    "                features[i,feature_position['time_between_questions_{}lag'.format(l)]] = time - user_dict[\n",
    "                    user_id]['timestamp_lst'][-l]\n",
    " \n",
    "        for l in range(2,5):\n",
    "            if len(user_dict[user_id]['timestamp_answ_incorr']) < l:\n",
    "                features[i,feature_position['timediff_{}_last_incorr_answ'.format(l)]] = np.nan\n",
    "            if len(user_dict[user_id]['timestamp_answ_incorr']) >= l:\n",
    "                features[i,feature_position['timediff_{}_last_incorr_answ'.format(l)]] = time - user_dict[\n",
    "                    user_id]['timestamp_answ_incorr'][-l]\n",
    "          \n",
    "        features[i,feature_position['previous_questions']]=previous_questions_temp\n",
    "        features[i,feature_position['answered_correctly_lagged_sum']]=answered_correctly_lagged_sum_temp\n",
    "        features[i,feature_position['previous_answered_correctly'\n",
    "                                   ]] = answered_correctly_lagged_sum_temp / previous_questions_temp\n",
    "        \n",
    "        features[i,feature_position['previous_questions_difficulty']]=previous_questions_difficulty_temp\n",
    "        features[i,feature_position['prev_que_answ_corr']]=previous_questions_answ_corr_temp\n",
    "        features[i,feature_position['prev_que_answ_incorr']]=previous_questions_answ_incorr_temp\n",
    "        \n",
    "        features[i,feature_position['prev_que_answ_corr_min']] = prev_que_answ_corr_min_temp\n",
    "        features[i,feature_position['prev_que_answ_incorr_max']] = prev_que_answ_incorr_max_temp\n",
    "        \n",
    "        features[i,feature_position['answer_share']]=user_dict[user_id]['answer_{}_share'.format(int(\n",
    "            corr_answ))]\n",
    "        \n",
    "        if len(user_dict[user_id]['answered_correctly_history'])>350:\n",
    "            features[i,feature_position['previous_answered_correctly_rolling']] = sum(\n",
    "                answered_correctly_history_temp[-350:]) / 350\n",
    "        else:\n",
    "            features[i,feature_position['previous_answered_correctly_rolling']] = sum(\n",
    "                answered_correctly_history_temp) / previous_questions_temp\n",
    "        \n",
    "        for r_w in [200, 100, 50, 20]:\n",
    "            if len(user_dict[user_id]['answered_correctly_history'])>r_w:\n",
    "                features[i,feature_position['previous_answered_correctly_rolling_{}'.format(r_w)]] = sum(\n",
    "                answered_correctly_history_temp[-r_w:]) / r_w\n",
    "            else:\n",
    "                features[i,feature_position['previous_answered_correctly_rolling_{}'.format(r_w)]] = sum(\n",
    "                answered_correctly_history_temp) / previous_questions_temp\n",
    "        \n",
    "        user_dict[user_id]['prior_question_elapsed_time_sum'] += elap_time\n",
    "        \n",
    "        user_dict[user_id]['prior_question_elapsed_time_mean'] = user_dict[user_id][\n",
    "            'prior_question_elapsed_time_sum'] / previous_questions_temp\n",
    "        \n",
    "        user_dict[user_id]['prior_question_had_explanation_mean'] = user_dict[user_id][\n",
    "            'prior_question_had_explanation_sum'] / user_dict[user_id]['previous_questions']\n",
    "        \n",
    "        user_dict[user_id]['answered_correctly_history'].append(answ_corr)\n",
    "    \n",
    "    user_dict[user_id]['previous_answered_correctly'] = user_dict[user_id]['answered_correctly_sum'\n",
    "                                                            ] / user_dict[user_id]['previous_questions']\n",
    "    user_dict[user_id]['answered_correctly_mean_sum'] += que_corr\n",
    "    user_dict[user_id]['answered_correctly_mean_weight'] += (que_corr * answ_corr)\n",
    "    user_dict[user_id]['answered_incorrectly_mean_weight'] += (que_corr * (1-answ_corr))\n",
    "        \n",
    "    user_dict[user_id]['previous_questions_difficulty'] =  user_dict[user_id]['answered_correctly_mean_sum'\n",
    "                                                        ] / user_dict[user_id]['previous_questions']\n",
    "    user_dict[user_id]['prev_que_answ_corr'] =  user_dict[user_id]['answered_correctly_mean_weight'\n",
    "                                                ] / user_dict[user_id]['answered_correctly_sum']\n",
    "    user_dict[user_id]['prev_que_answ_incorr'] =  user_dict[user_id]['answered_incorrectly_mean_weight'\n",
    "                                                    ] / user_dict[user_id]['answered_incorrectly_sum']\n",
    "    \n",
    "    if ((que_corr < user_dict[user_id]['prev_que_answ_corr_min']) | (user_dict[user_id][\n",
    "        'prev_que_answ_corr_min']==0)) & (answ_corr==1):\n",
    "        user_dict[user_id]['prev_que_answ_corr_min'] = que_corr\n",
    "    elif user_dict[user_id]['prev_que_answ_corr_min']==0:\n",
    "        user_dict[user_id]['prev_que_answ_corr_min']==np.nan\n",
    "        \n",
    "    if ((que_corr > user_dict[user_id]['prev_que_answ_incorr_max']) | (user_dict[user_id][\n",
    "        'prev_que_answ_incorr_max']==0)) & (answ_corr==0):\n",
    "        user_dict[user_id]['prev_que_answ_incorr_max'] = que_corr\n",
    "    elif user_dict[user_id]['prev_que_answ_incorr_max']==0:\n",
    "        user_dict[user_id]['prev_que_answ_incorr_max']==np.nan\n",
    "        \n",
    "    user_dict[user_id]['prior_question_had_explanation_sum'] += exp\n",
    "    \n",
    "    user_dict[user_id]['answer_{}_share'.format(user_answ)] = user_dict[user_id][\n",
    "        'answer_{}'.format(user_answ)] / user_dict[user_id]['previous_questions']\n",
    "    \n",
    "    features[i,feature_position['prior_question_had_explanation_mean']] = user_dict[user_id][\n",
    "        'prior_question_had_explanation_mean']\n",
    "    features[i,feature_position['prior_question_elapsed_time_mean']] = user_dict[user_id][\n",
    "        'prior_question_elapsed_time_mean']\n",
    "    features[i,feature_position['prior_question_elapsed_time_sum']] = user_dict[user_id][\n",
    "        'prior_question_elapsed_time_sum']\n",
    "    \n",
    "    previous_questions_temp = user_dict[user_id]['previous_questions']\n",
    "    answered_correctly_lagged_temp = user_dict[user_id]['answered_correctly']\n",
    "    answered_correctly_lagged_sum_temp = user_dict[user_id]['answered_correctly_sum']\n",
    "    previous_answered_correctly_temp = user_dict[user_id]['previous_answered_correctly']\n",
    "    previous_questions_difficulty_temp = user_dict[user_id]['previous_questions_difficulty']\n",
    "    previous_questions_answ_corr_temp = user_dict[user_id]['prev_que_answ_corr']\n",
    "    previous_questions_answ_incorr_temp = user_dict[user_id]['prev_que_answ_incorr']\n",
    "    prev_que_answ_corr_min_temp = user_dict[user_id]['prev_que_answ_corr_min']                                                          \n",
    "    prev_que_answ_incorr_max_temp = user_dict[user_id]['prev_que_answ_incorr_max']\n",
    "    answered_correctly_history_temp = user_dict[user_id]['answered_correctly_history']\n",
    "    answered_correctly_mean_lagged_temp =  que_corr\n",
    "    previous_answered_correctly_std_temp = user_dict[user_id]['previous_answered_correctly_std']\n",
    "    task_container_temp = task_id\n",
    "    overperformance_temp = user_dict[user_id]['overperformance']\n",
    "    underperformance_temp = user_dict[user_id]['underperformance']\n",
    "    \n",
    "    user_performance_temp = user_dict[user_id]['user_performance']\n",
    "    \n",
    "    user_dict[user_id]['timestamp'] = time\n",
    "    user_dict[user_id]['timestamp_lst'].append(time)\n",
    "\n",
    "    if answ_corr == 1:\n",
    "        user_dict[user_id]['timestamp_answ_corr'].append(time)\n",
    "    else:\n",
    "        user_dict[user_id]['timestamp_answ_incorr'].append(time)\n",
    "    \n",
    "del user_dict\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second question clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clustering = features[:,[1,2,3,4,5,15,16,17,37,39]]\n",
    "X_clustering = np.concatenate((questions.reshape(-1,1),np.nan_to_num(X_clustering), np.nan_to_num(\n",
    "    question_had_explanation.reshape(-1,1)), np.nan_to_num(question_elapsed_time.reshape(-1,1)\n",
    "    ),np.nan_to_num(timestamp.reshape(-1,1))), axis=1)\n",
    "X_clustering = pd.DataFrame(X_clustering).groupby(0).mean()\n",
    "scaler = StandardScaler()\n",
    "X_clustering = pd.DataFrame(scaler.fit_transform(X_clustering))\n",
    "clustering = KMeans(20, n_init=30, max_iter=1000)\n",
    "X_clustering['clusters_que'] = clustering.fit_predict(X_clustering)\n",
    "X_clustering.set_index(np.unique(questions), inplace=True)\n",
    "que_cluster_dict = X_clustering[['clusters_que']].to_dict(orient='index')\n",
    "for i, content_id in enumerate(tqdm(questions)):\n",
    "    features[i,feature_position['question_clusters_2']] = que_cluster_dict[content_id]['clusters_que']+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=lgb.Dataset(features[train_val_split==0],label=y[train_val_split==0])\n",
    "val_data=lgb.Dataset(features[train_val_split==1],label=y[train_val_split==1])\n",
    "\n",
    "param = {'num_leaves':200, 'objective':'binary', 'learning_rate':.1, 'bagging_fraction':0.5, 'bagging_freq':0,\n",
    "         'lambda_l2': 0.1, 'zero_as_missing':True}\n",
    "param['metric'] = ['auc']\n",
    "lgbm=lgb.train(param, train_data, num_boost_round=1500, verbose_eval=10, valid_sets=[train_data, val_data\n",
    "                                ], early_stopping_rounds=20, categorical_feature=[6,7,8,9,43,44])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm.save_model('lgbm_model.txt', num_iteration=lgbm.best_iteration)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
