{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Transformer model to predict students' success\n",
    "\n",
    "The implemented model is based on Shin et al.: SAINT+: Integrating Temporal Features for EdNet Correctness Prediction ([arXiv](https://arxiv.org/abs/2010.12042)).\n",
    "\n",
    "Features for the encoder:\n",
    "- question id\n",
    "- part (category)\n",
    "- relative position\n",
    "\n",
    "Features for the decoder:\n",
    "- lagged response\n",
    "- time between questions (in days)\n",
    "- relative position\n",
    "\n",
    "Model specification:\n",
    "- Model dimension (size of embeddings): 128\n",
    "- Encoder layers: 2\n",
    "- Deconder layers: 2\n",
    "- Heads: 4\n",
    "- Feed forward: 512\n",
    "- Lenght of a sequence (window size): 100\n",
    "- Batch size: 128 users (up to 4 sequences)\n",
    "- Adam optimizer with 0.001 learning rate and a scheduler\n",
    "<br>\n",
    "\n",
    "### Vasvani et al. (2017):  [Attention is all you need](https://arxiv.org/abs/1706.03762) <br>\n",
    "\n",
    "<img style=\"float: left;\" src=\"transformer_model.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import gc\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import dill\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    \"timestamp\": \"int64\",\n",
    "    \"user_id\": \"int32\",\n",
    "    \"content_id\": \"int16\",\n",
    "    \"content_type_id\": \"int8\",\n",
    "    \"task_container_id\": \"int16\",\n",
    "    \"answered_correctly\": \"int8\",\n",
    "    \"prior_question_elapsed_time\": \"float32\", \n",
    "    \"prior_question_had_explanation\": \"int8\"\n",
    "    }\n",
    "\n",
    "data = pd.read_csv('train.csv', dtype=dtypes, usecols=[\"user_id\",\"timestamp\",\"content_id\",\n",
    "                    \"content_type_id\",\"task_container_id\",\"answered_correctly\",\"prior_question_elapsed_time\",\n",
    "                    \"prior_question_had_explanation\"])\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_csv('questions.csv')\n",
    "\n",
    "questions = questions[['question_id','part']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['content_type_id']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.join(questions[['question_id','part']].set_index('question_id'), on='content_id', how='left')\n",
    "   \n",
    "del questions\n",
    "\n",
    "data['part'] = data['part'].astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['answered_correctly_lagged'] = data.groupby(['user_id'])['answered_correctly'].shift(1).astype(\"float32\")\n",
    "\n",
    "data['time_between_questions'] = data.groupby('user_id')['timestamp'].diff()\n",
    "\n",
    "data['counter'] = data.groupby('user_id')['answered_correctly'].cumcount().astype(\"uint16\") + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[['user_id','answered_correctly']]\n",
    "\n",
    "x = data[['user_id','content_id','counter','part','answered_correctly_lagged','time_between_questions']]\n",
    "\n",
    "del data\n",
    "\n",
    "x['answered_correctly_lagged'] = x.loc[:,'answered_correctly_lagged'].fillna(2)\n",
    "x['time_between_questions'] = x['time_between_questions'].fillna(366)\n",
    "\n",
    "for var in x.columns:\n",
    "    x[var] = x[var].fillna(0)\n",
    "    \n",
    "x['time_between_questions'] = (x['time_between_questions']/(60000*60*24)).apply(int).clip(0,366)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lst = [d for d in x.groupby('user_id')]\n",
    "y_lst = [d for d in y.groupby('user_id')]\n",
    "\n",
    "t_dict = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for x_item, y_item in zip(tqdm(x_lst), y_lst):\n",
    "    t_dict['x'][x_item[0]]=x_item[1].iloc[:,1:].values\n",
    "    t_dict['y'][y_item[0]]=y_item[1].iloc[:,1:].values\n",
    "\n",
    "del x_lst\n",
    "del y_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.question_id_embedding = nn.Embedding(13523+1, d_model)\n",
    "        self.positional_embedding = nn.Embedding(100+1, d_model)\n",
    "        self.part_embedding = nn.Embedding(7+1, d_model)\n",
    "        self.correctness_embedding = nn.Embedding(2+1, d_model)\n",
    "        self.time_between_questions_embedding = nn.Embedding(365+2, d_model)\n",
    "        self.transformer = nn.Transformer(d_model=d_model, \n",
    "                                  nhead=4, \n",
    "                                  num_encoder_layers= 2,\n",
    "                                  num_decoder_layers= 2, \n",
    "                                  dim_feedforward=512, \n",
    "                                  dropout=0.0, \n",
    "                                  activation='relu')\n",
    "        self.linear2output = nn.Linear(d_model, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, question_id, part, correctness, time_between_que, position, mask_triu,\n",
    "                padding_mask):\n",
    "        question_id_emb = self.question_id_embedding(question_id)\n",
    "        position_emb = self.positional_embedding(position)\n",
    "        part_emb = self.part_embedding(part)\n",
    "        correctness_emb = self.correctness_embedding(correctness)\n",
    "        time_between_que_emb = self.time_between_questions_embedding(time_between_que)\n",
    "        exercise_emb = question_id_emb + position_emb + part_emb\n",
    "        response_emb = correctness_emb + position_emb + time_between_que_emb \n",
    "        output = self.transformer(exercise_emb, response_emb, src_mask=mask_triu, tgt_mask=mask_triu,\n",
    "                                  memory_mask=mask_triu, src_key_padding_mask=padding_mask,\n",
    "                                  tgt_key_padding_mask=padding_mask, memory_key_padding_mask=padding_mask)\n",
    "        output = self.linear2output(output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "transformer = Transformer(128)\n",
    "transformer.to(device)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "criterion.to(device)\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=learning_rate)\n",
    "\n",
    "lambda1 = lambda epoch: 1 / (1 + 0.05*(epoch-1))\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = t_dict['x'].keys()\n",
    "user_list = random.sample(list(user_list), len(user_list))\n",
    "\n",
    "train_split = int(len(user_list)*0.9)\n",
    "user_train = user_list[:train_split]\n",
    "user_test = user_list[train_split:]\n",
    "\n",
    "training_size = len(user_train)\n",
    "training_batches = training_size // batch_size\n",
    "\n",
    "test_size = len(user_test)\n",
    "test_batches = test_size // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    user_train_epoch = random.sample(list(user_train), len(user_train))\n",
    "    \n",
    "################################# Training ##################################\n",
    "    i = 0\n",
    "        \n",
    "    for batch in range(1, training_batches + 1):\n",
    "        \n",
    "        input_seq_l = []\n",
    "        input_seq_len = []\n",
    "        y_tensor_l = []\n",
    "        y_tensor_len = []\n",
    "\n",
    "        for j in range(i, i+batch_size):\n",
    "            seq = t_dict['x'][user_train_epoch[j]]\n",
    "            if len(seq)>100:\n",
    "                if len(seq)>500:\n",
    "                    seq = seq[-500:]\n",
    "                a = random.randint(0,100)\n",
    "                b = a\n",
    "                while b <= len(seq)-100:\n",
    "                    input_seq = seq[b:b+100]\n",
    "                    input_seq = torch.from_numpy(input_seq).long().to(device)\n",
    "                    input_seq_l.append(input_seq)\n",
    "                    input_seq_len.append(input_seq.size()[0])\n",
    "                    b += 100\n",
    "            else:\n",
    "                input_seq = torch.from_numpy(seq).long().to(device)\n",
    "                input_seq_l.append(input_seq)\n",
    "                input_seq_len.append(input_seq.size()[0])\n",
    "        \n",
    "            y_tensor = torch.tensor(t_dict['y'][user_train_epoch[j]], dtype=torch.float, device=device)\n",
    "            if len(y_tensor)>100:\n",
    "                if len(y_tensor)>500:\n",
    "                    y_tensor = y_tensor[-500:]\n",
    "                while a <= len(y_tensor)-100:\n",
    "                    y_tensor_b = y_tensor[a:a+100]\n",
    "                    y_tensor_l.append(y_tensor_b)\n",
    "                    y_tensor_len.append(y_tensor_b.size()[0]) \n",
    "                    a += 100\n",
    "            else:\n",
    "                y_tensor_l.append(y_tensor)\n",
    "                y_tensor_len.append(y_tensor.size()[0])\n",
    "          \n",
    "        input_seq_p = pad_sequence(input_seq_l, padding_value=0)\n",
    "\n",
    "        y_tensor_p = pad_sequence(y_tensor_l)\n",
    "\n",
    "        y_tensor_p = y_tensor_p.view(y_tensor_p.size()[0],y_tensor_p.size()[1],1)\n",
    "        y_tensor_p.to(device)\n",
    "    \n",
    "        input_seq_p.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        position = torch.arange(1, input_seq_p[:,:,0].shape[0]+1).to(device).unsqueeze(0).repeat(input_seq_p[\n",
    "            :,:,0].shape[1], 1).transpose(0,1)\n",
    "        mask_triu = torch.triu(torch.ones(input_seq_p[:,:,3].size()[0], input_seq_p[:,:,3].size()[0])\n",
    "                               ==1, diagonal=1)\n",
    "        mask_triu = mask_triu.to(device)\n",
    "        \n",
    "        padding_mask = (input_seq_p[:,:,1]==0).transpose(0, 1)\n",
    "        padding_mask = padding_mask.to(device)\n",
    "        \n",
    "        output = transformer(input_seq_p[:,:,0], input_seq_p[:,:,2], input_seq_p[:,:,3], input_seq_p[:,:,4\n",
    "                    ], position, mask_triu, padding_mask)\n",
    "        \n",
    "        loss_batch = criterion(output, y_tensor_p)\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train = loss_batch.detach().item()\n",
    "        del loss_batch\n",
    "        \n",
    "        outputs = output.detach()\n",
    "        del output\n",
    "        \n",
    "        y_tensors = y_tensor_p.detach()\n",
    "        del y_tensor_p\n",
    "        \n",
    "        y_pred = outputs[y_tensor_len[0]-1,0]\n",
    "        y_true = y_tensors[y_tensor_len[0]-1,0]\n",
    "        \n",
    "        for k, seqlen in enumerate(y_tensor_len[1:], start=1):\n",
    "            y_pred = torch.cat((y_pred, outputs[seqlen-1,k]))\n",
    "            y_true = torch.cat((y_true, y_tensors[seqlen-1,k]))\n",
    "                \n",
    "        if batch==1:\n",
    "            y_hat_train = y_pred\n",
    "            y_true_train = y_true\n",
    "            loss = loss_train\n",
    "        else:\n",
    "            y_hat_train = torch.cat((y_hat_train, y_pred))\n",
    "            y_true_train = torch.cat((y_true_train, y_true))\n",
    "            loss = loss + loss_train\n",
    "            \n",
    "        i += batch_size\n",
    "\n",
    "################################ Validation #########################################\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for batch in range(1, test_batches + 1):\n",
    "        \n",
    " \n",
    "        input_seq_l = []\n",
    "        input_seq_len = []\n",
    "        y_tensor_l = []\n",
    "        y_tensor_len = []\n",
    "\n",
    "        for j in range(i, i+batch_size):\n",
    "            seq_val = t_dict['x'][user_test[j]]\n",
    "            if len(seq_val)>100:\n",
    "                seq_val = seq_val[-100:]\n",
    "                \n",
    "            input_seq_val = torch.from_numpy(seq_val).long().to(device)\n",
    "            input_seq_l.append(input_seq_val)\n",
    "    \n",
    "            y_tensor_val = torch.tensor(t_dict['y'][user_test[j]], dtype=torch.float, device=device)\n",
    "            if len(y_tensor_val)>100:\n",
    "                y_tensor_val = y_tensor_val[-100:]\n",
    "            y_tensor_l.append(y_tensor_val)\n",
    "            y_tensor_len.append(y_tensor_val.size()[0])\n",
    "    \n",
    "        input_seq_p_val = pad_sequence(input_seq_l, padding_value=0)\n",
    "        y_tensor_p_val = pad_sequence(y_tensor_l)\n",
    "        y_tensor_p_val = y_tensor_p_val.view(y_tensor_p_val.size()[0],y_tensor_p_val.size()[1],1)\n",
    "        y_tensor_p_val.to(device)\n",
    "        input_seq_p_val.to(device)\n",
    "        \n",
    "        position = torch.arange(1, input_seq_p_val[:,:,0].shape[0]+1).to(device).unsqueeze(0).repeat(\n",
    "            input_seq_p_val[:,:,0].shape[1], 1).transpose(0,1)\n",
    "        mask_triu = torch.triu(torch.ones(input_seq_p_val[:,:,3].size()[0], input_seq_p_val[:,:,3].size()[0])\n",
    "                               ==1, diagonal=1)\n",
    "        mask_triu = mask_triu.to(device)\n",
    "        \n",
    "        padding_mask = (input_seq_p_val[:,:,1]==0).transpose(0, 1)\n",
    "        padding_mask = padding_mask.to(device)\n",
    "        \n",
    "        output_val = transformer(input_seq_p_val[:,:,0], input_seq_p_val[:,:,2], input_seq_p_val[:,:,3\n",
    "                    ], input_seq_p_val[:,:,4], position, mask_triu, padding_mask)\n",
    "        \n",
    "        loss_batch_val = criterion(output_val, y_tensor_p_val)\n",
    "        \n",
    "        loss_val = loss_batch_val.detach().item()\n",
    "        del loss_batch_val\n",
    "        \n",
    "        y_tensors_val = y_tensor_p_val.detach()\n",
    "        del y_tensor_p_val\n",
    "        \n",
    "        outputs_val = output_val.detach()\n",
    "        del output_val\n",
    "        \n",
    "        y_pred_val = outputs_val[y_tensor_len[0]-1,0]\n",
    "        y_true_val = y_tensors_val[y_tensor_len[0]-1,0]\n",
    "        \n",
    "        for k, seqlen in enumerate(y_tensor_len[1:], start=1):\n",
    "            y_pred_val = torch.cat((y_pred_val, outputs_val[seqlen-1,k]))\n",
    "            y_true_val = torch.cat((y_true_val, y_tensors_val[seqlen-1,k]))  \n",
    "\n",
    "        if batch==1:\n",
    "            y_hat_test = y_pred_val\n",
    "            y_true_test = y_true_val\n",
    "            loss_test = loss_val\n",
    "        else:\n",
    "            y_hat_test = torch.cat((y_hat_test, y_pred_val))\n",
    "            y_true_test = torch.cat((y_true_test, y_true_val))\n",
    "            loss_test = loss_test + loss_val\n",
    "            \n",
    "        i += batch_size\n",
    "   \n",
    "    y_hat_train = y_hat_train.detach().cpu().numpy()  \n",
    "    y_true_train = y_true_train.detach().cpu().numpy()\n",
    "    \n",
    "    auc_score_train = roc_auc_score(y_true_train, y_hat_train)\n",
    "    \n",
    "    loss = loss / training_batches\n",
    "    \n",
    "    y_hat_test = y_hat_test.detach().cpu().numpy()  \n",
    "    y_true_test = y_true_test.detach().cpu().numpy()\n",
    "\n",
    "    auc_score_val = roc_auc_score(y_true_test, y_hat_test)\n",
    "    \n",
    "    loss_test = loss_test / test_batches\n",
    "    \n",
    "    print('Epoch: {}/{}, Batches: {}/{}.............'.format(epoch, epochs, training_batches, training_batches\n",
    "                                                            ), end=' ')\n",
    "    print(\"Loss: {:.4f}, ROC AUC: {:.4f}, Loss val: {:.4f}, ROC AUC val: {:.4f}\".format(\n",
    "        loss, auc_score_train, loss_test, auc_score_val))\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(transformer, \"/kaggle/working/transformer_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
